{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS-Tagging and Its Applications                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is POS-tagging?\n",
    "\n",
    "\n",
    "The obvious first step in understanding POS-tagging is to expand the acronym – Part-Of-Speech tagging. Now, that makes things a lot easier now, doesn't it? As the name suggests, it is the process of tagging words in a textual input with their appropriate part of speech. We've already discussed this before briefly, particularly when dealing with spaCy and its language models. So, while we know that POS-tagging refers to the action of tagging words with their POS, we haven't talked very much about what exactly a part of speech in natural language (and in particular, English) is, and why it might be relevant to us in the realm of text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Noun - The name of a person, place, thing, or idea\n",
    "\n",
    "- Verb - The action or beingAdjective - This modifies or describes a noun or a pronoun\n",
    "\n",
    "- Adverb - This modifies or describes a verb, adjective, or another adverb\n",
    "\n",
    "- Pronoun - The word to be used in place of a noun\n",
    "\n",
    "- Preposition - The word placed before a noun or pronoun to form a phrase modifying another word in the sentence\n",
    "\n",
    "- Conjunction - This joins words, phrases, or clauses\n",
    "\n",
    "- Interjection - A word used to express emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "text = nltk.word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_sents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4122ffa96792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbigram_tagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBigramTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbigram_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_sents' is not defined"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "bigram_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_0 = nlp(u'Mathieu and I went to the park.')\n",
    "sent_1 = nlp(u'If Clement was asked to take out the garbage, he would refuse.')\n",
    "sent_2 = nlp(u'Baptiste was in charge of the refuse treatment center.')\n",
    "sent_3 = nlp(u'Marie took out her rather suspicious and fishy cat to go fish for fish.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathieu | PROPN | NNP\n",
      "and | CCONJ | CC\n",
      "I | PRON | PRP\n",
      "went | VERB | VBD\n",
      "to | ADP | IN\n",
      "the | DET | DT\n",
      "park | NOUN | NN\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "for token in sent_0:\n",
    "    print('{} | {} | {}'.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few of the tags here – Mathieu is a name, and it is correctly marked as a proper noun, went is a verb, and the park is a noun – all that we would expect it to be. We previously talked about the word refuse, and how it can be both a noun and a verb.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If | ADP | IN\n",
      "Clement | PROPN | NNP\n",
      "was | VERB | VBD\n",
      "asked | VERB | VBN\n",
      "to | PART | TO\n",
      "take | VERB | VB\n",
      "out | PART | RP\n",
      "the | DET | DT\n",
      "garbage | NOUN | NN\n",
      ", | PUNCT | ,\n",
      "he | PRON | PRP\n",
      "would | VERB | MD\n",
      "refuse | VERB | VB\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "for token in sent_1:\n",
    "    print('{} | {} | {}'.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the word refuse is a verb, as we expect it to be. The word garbage is a noun and is the object which our friend Clement is refusing to take out. Our next sentence is also an example involving garbage, but here the word refuse is the substance being treated in the plant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baptiste | PROPN | NNP\n",
      "was | VERB | VBD\n",
      "in | ADP | IN\n",
      "charge | NOUN | NN\n",
      "of | ADP | IN\n",
      "the | DET | DT\n",
      "refuse | ADJ | JJ\n",
      "treatment | NOUN | NN\n",
      "center | NOUN | NN\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "for token in sent_2:\n",
    "    print('{} | {} | {}'.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila! As we wanted to see, the refuse word is now correctly tagged as a noun. With the context of it appearing as something Baptiste is in charge of, it is appropriately changed to a noun. In fact, the last three words are all nouns, or is something which we call a noun phrase. We will deal with this term in more detail in the chapter on dependency parsing.Let's now have a look at our last sentence:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marie | PROPN | NNP\n",
      "took | VERB | VBD\n",
      "out | PART | RP\n",
      "her | PRON | PRP\n",
      "rather | ADV | RB\n",
      "suspicious | ADJ | JJ\n",
      "and | CCONJ | CC\n",
      "fishy | ADJ | JJ\n",
      "cat | NOUN | NN\n",
      "to | PART | TO\n",
      "go | VERB | VB\n",
      "fish | NOUN | NN\n",
      "for | ADP | IN\n",
      "fish | NOUN | NN\n",
      ". | PUNCT | .\n"
     ]
    }
   ],
   "source": [
    "for token in sent_3:\n",
    "    print('{} | {} | {}'.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this sentence was to attempt to fool our tagger with different variations of the word fish, but our tagger could easily tell the difference in the appropriate context. Our model is a machine learning model which, among other training features, uses the tags of the previous words and upcoming words to decide the new tag – the word fishy was tagged as a verb partly because of the fact that a noun comes right after, partly because a conjunction came before, and also possibly because it ends with the letter y. Most machine learning models take multiple features into account when deciding a new label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
