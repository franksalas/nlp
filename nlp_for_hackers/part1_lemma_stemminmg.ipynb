{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing and Stemming\n",
    "One of the most useful operations in Natural Language Processing is finding the\n",
    "base form of a word. This is such a common operation because it’s so useful in so\n",
    "many situations. Let’s take the case of a search engine which should provide similar\n",
    "results for different queries (e.g. “write book” / “writing books”). In order for the\n",
    "search engine to provide similar results, it has to find the base form of the words.\n",
    "There are two distinct approaches to this task:\n",
    "a. Stemming, which is an algorithmic method of a shaving off prefixes and\n",
    "suffixes from a given word form\n",
    "b. Lemmatizing, which is a corpus-based method for finding the base form of a\n",
    "word\n",
    "\n",
    "\n",
    "There are fundamental differences between these two methods, each having advantages\n",
    "and disadvantages. Here’s a short comparison:\n",
    "- Both stemmers and lemmatizers bring inflected words to the same form, or at\n",
    "least they try to\n",
    "- Stemmers can’t guarantee a valid word as a result (in fact, the result usually\n",
    "isn’t a valid word)\n",
    "- Lemmatizers always return a valid word (the dictionary form)\n",
    "- Stemmers are faster\n",
    "- Lemmatizers depend on a corpus (basically a dictionary) to perform the task\n",
    "\n",
    "\n",
    "## How stemmers work\n",
    "When stemming, what you actually do is to apply various rules to a specific word\n",
    "form until you reduce the word to its basic form and no other rule can be applied.\n",
    "This method is fast and also, the best choice for most real-world applications. The\n",
    "downside of stemming is the incertitude of the result because it usually isn’t a valid\n",
    "word, but on the bright side, you can have two related words which can resolute to\n",
    "the same stem. Let’s see an example:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "friend\n",
      "friend\n",
      "friend\n",
      "drink\n",
      "drunk\n",
      "slowli\n"
     ]
    }
   ],
   "source": [
    "#Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "# all resolve to `friend`\n",
    "print(stemmer.stem('friend'))\n",
    "print(stemmer.stem('friends'))\n",
    "print(stemmer.stem('friendly'))\n",
    "# Not working well with irregulars\n",
    "print(stemmer.stem('drink')) # `drink`\n",
    "print(stemmer.stem('drunk')) # `drunk`\n",
    "# Not a proper word (`slowli`)\n",
    "print(stemmer.stem('slowly'))\n",
    "# Works with non-existing words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How lemmatizers work\n",
    "You can think of lemmatizers as a huge Python dictionary where the word forms\n",
    "are the keys and the base form of the words are the values. Because two words\n",
    "with different parts of speech can have the same form, we need to specify the part\n",
    "of speech.\n",
    "\n",
    "*Wordnet Lemmatizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haunting\n",
      "haunt\n",
      "friend\n",
      "friend\n",
      "friendly\n",
      "drink\n",
      "drink\n",
      "slowly\n",
      "xyzing\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Different parts of speech with the same form\n",
    "print(lemmatizer.lemmatize('haunting', 'n')) # `haunting`\n",
    "print(lemmatizer.lemmatize('haunting', 'v')) # `haunt`\n",
    "# Resolve to `friend`\n",
    "print(lemmatizer.lemmatize('friend', 'n'))\n",
    "print(lemmatizer.lemmatize('friends', 'n'))\n",
    "# Resolving to `friendly` because it's a different part of speech\n",
    "print(lemmatizer.lemmatize('friendly', 'a'))\n",
    "# Working well with irregulars\n",
    "print(lemmatizer.lemmatize('drink', 'v')) # `drink`\n",
    "print(lemmatizer.lemmatize('drunk', 'v')) # `drink`\n",
    "# Always a proper word (`slowly`)\n",
    "\n",
    "\n",
    "\n",
    "print(lemmatizer.lemmatize('slowly', 'r'))\n",
    "# Not working with non-existing words (`xyzing`)\n",
    "print(lemmatizer.lemmatize('xyzing', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
