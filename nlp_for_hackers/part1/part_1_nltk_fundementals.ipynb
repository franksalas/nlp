{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Fundamentals\n",
    "\n",
    "NLTK (Natural Language ToolKit) is probably the most well known Python Natural\n",
    "Language Processing library. You can find the official website here: http://www.nltk.org/2.\n",
    "There’s a lot of discussion around it whether it really is a production-ready library.\n",
    "I believe that the pre-trained models that come with it are not the best out there,\n",
    "but NLTK is definitely a great library for:\n",
    "\n",
    "- Learning NLP - the API is simple & well-designed, full of good didactic examples\n",
    "- Prototyping - before building performant systems, you should build a prototype\n",
    "so you can prove how cool your new app is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Text\n",
    "Until now, you probably haven’t put a lot of thought into how difficult can the task of\n",
    "splitting text into sentences and/or words be. Let’s identify the most common issues\n",
    "using a sample text from NLTK and see how the NLTK sentence splitter performs in\n",
    "various situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMPLE SUPPLIES LIMIT U.S. STRIKE'S OIL PRICE IMPACT\n",
      "  Ample supplies of OPEC crude weighing on\n",
      "  world markets helped limit and then reverse oil price gains\n",
      "  that followed the U.S. Strike on an Iranian oil platform in the\n",
      "  Gulf earlier on Monday, analysts said.\n",
      "      December loading rose to 19.65 dlrs, up 45 cents before\n",
      "  falling to around 19.05/15 later, unchanged from last Friday.\n",
      "      \"Fundamentals are awful,\" said Philip Lambert, analyst with\n",
      "  stockbrokers Kleinwort Grieveson, adding that total OPEC\n",
      "  production in the first week of October could be above 18.5 mln\n",
      "  bpd, little changed from September levels.\n",
      "      Peter Nicol, analyst at Chase Manhattan Bank, said OPEC\n",
      "  production could be about 18.5-19.0 mln in October. Reuter and\n",
      "  International Energy Agency (IEA) estimates put OPEC September\n",
      "  production at 18.5 mln bpd.\n",
      "      The U.S. Attack was in retaliation of last Friday's hit of\n",
      "  a Kuwaiti oil products tanker flying the U.S. Flag, the Sea\n",
      "  Isle City. It was struc ...\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "print(reuters.raw('test/21131')[:1000], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- not all punctuation marks indicate the end of a sentence (from the example\n",
    "above: “U.S.”, “19.65”, “19.05/15”, etc. )\n",
    "- not all sentences end with a punctuation mark (e.g. text from social platforms)\n",
    "- not all sentences start with a capitalized letter (e.g. some sentences start with\n",
    "a quotation mark or with numbers)\n",
    "- not all capitalized letters mark the start of a sentence (from the example above:\n",
    "“The U.S. Attack”, “U.S. Flag”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sentences=9\n",
      "\n",
      "\n",
      "AMPLE SUPPLIES LIMIT U.S. STRIKE'S OIL PRICE IMPACT\n",
      "  Ample supplies of OPEC crude weighing on\n",
      "  world markets helped limit and then reverse oil price gains\n",
      "  that followed the U.S. Strike on an Iranian oil platform in the\n",
      "  Gulf earlier on Monday, analysts said. \n",
      "\n",
      "December loading rose to 19.65 dlrs, up 45 cents before\n",
      "  falling to around 19.05/15 later, unchanged from last Friday. \n",
      "\n",
      "\"Fundamentals are awful,\" said Philip Lambert, analyst with\n",
      "  stockbrokers Kleinwort Grieveson, adding that total OPEC\n",
      "  production in the first week of October could be above 18.5 mln\n",
      "  bpd, little changed from September levels. \n",
      "\n",
      "Peter Nicol, analyst at Chase Manhattan Bank, said OPEC\n",
      "  production could be about 18.5-19.0 mln in October. \n",
      "\n",
      "Reuter and\n",
      "  International Energy Agency (IEA) estimates put OPEC September\n",
      "  production at 18.5 mln bpd. \n",
      "\n",
      "The U.S. \n",
      "\n",
      "Attack was in retaliation of last Friday's hit of\n",
      "  a Kuwaiti oil products tanker flying the U.S. \n",
      "\n",
      "Flag, the Sea\n",
      "  Isle City. \n",
      "\n",
      "It was struc \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "sentences = nltk.sent_tokenize(reuters.raw('test/21131')[:1000])\n",
    "print(\"#sentences={0}\\n\\n\".format(len(sentences)))\n",
    "for sent in sentences:\n",
    "    print(sent, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results are not perfect: the last three sentences are actually\n",
    "a single sentence. The NLTK sentence splitter was fooled by the full stop and the\n",
    "capitalized letter.\n",
    "The NLTK splitter is a rule-based system that keeps lists of abbreviations, words that\n",
    "usually go together and words that appear at the start of a sentence. Let me show\n",
    "you an example where the NLTK splitter doesn’t fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The U.S. Army is a good example.']\n"
     ]
    }
   ],
   "source": [
    "#Introducing nltk.sent_tokenize, take 2\n",
    "import nltk\n",
    "print(nltk.sent_tokenize(\"The U.S. Army is a good example.\"))\n",
    "# ['The U.S. Army is a good example.'] - only one sentence, no false splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s talk about splitting sentences into words. The process is almost the same, but\n",
    "the solution for word tokenization is easier and more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'U.S.', 'Army', 'is', 'a', 'good', 'example', '.']\n"
     ]
    }
   ],
   "source": [
    "#Introducing nltk.word_tokenize\n",
    "import nltk\n",
    "print(nltk.word_tokenize('The U.S. Army is a good example.'))\n",
    "# ['The', 'U.S.', 'Army', 'is', 'a', 'good', 'example', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `word_tokenize` function uses the `nltk.tokenize.treebank.TreebankWordTokenizer` class.\n",
    "\n",
    "The `TreebankWordTokenizer` is a rule-based system that splits sentences into words\n",
    "according to the rules in the Penn Treebank corpus that makes heavy use of regular\n",
    "expressions.\n",
    "\n",
    "Here are the rules followed by the word tokenizer, extracted from the NLTK\n",
    "documentation:\n",
    "- split standard contractions, e.g. “don’t” ! “do n’t” and “they’ll” ! “they ‘ll”\n",
    "- treat most punctuation characters as separate tokens\n",
    "- split off commas and single quotes, when followed by whitespace\n",
    "- separate periods that appear at the end of line\n",
    "\n",
    "\n",
    "\n",
    "## Building a vocabulary\n",
    "You will often want to compute some word statistics. NLTK has some helpful classes\n",
    "to quickly compute the metrics you’re after, like `nltk.FreqDist`. Here’s an example of\n",
    "how you can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vocabulary\n",
    "import nltk\n",
    "fdist = nltk.FreqDist(nltk.corpus.reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fdist) # dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 41600 samples and 1720901 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 94687, ',': 72360, 'the': 58251, 'of': 35979, 'to': 34035, 'in': 26478, 'said': 25224, 'and': 25043, 'a': 23492, 'mln': 18037, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 94687), (',', 72360), ('the', 58251), ('of', 35979), ('to', 34035), ('in', 26478), ('said', 25224), ('and', 25043), ('a', 23492), ('mln', 18037)]\n"
     ]
    }
   ],
   "source": [
    "# top 10 most frequent words\n",
    "print(fdist.most_common(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346\n"
     ]
    }
   ],
   "source": [
    "# get the count of the word `stock`\n",
    "print(fdist['stock']) # 2346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# get the count of the word `stork`\n",
    "print(fdist['stork']) # 0 :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033849129031826936\n"
     ]
    }
   ],
   "source": [
    "# get the frequency of the word `the`\n",
    "print(fdist.freq('the')) # 0.033849129031826936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RIFT',\n",
       " 'Mounting',\n",
       " 'inflict',\n",
       " 'Move',\n",
       " 'Unofficial',\n",
       " 'Sheen',\n",
       " 'Safe',\n",
       " 'avowed',\n",
       " 'VERMIN',\n",
       " 'EAT',\n",
       " 'vermin',\n",
       " 'kilolitres',\n",
       " 'kl',\n",
       " 'Janunary',\n",
       " 'pineapples',\n",
       " 'Hasrul',\n",
       " 'Paian',\n",
       " 'sawn',\n",
       " 'Goodall',\n",
       " 'Bundey',\n",
       " 'desposits',\n",
       " 'unrecoverable',\n",
       " 'Koh',\n",
       " 'scratch',\n",
       " 'forbidden',\n",
       " 'lame',\n",
       " 'duck',\n",
       " 'Regulations',\n",
       " 'Steagall',\n",
       " 'Meiko',\n",
       " 'devote',\n",
       " 'digesting',\n",
       " 'juggling',\n",
       " 'plentiful',\n",
       " 'BAIL',\n",
       " 'ATLC',\n",
       " 'bail',\n",
       " 'Cebu',\n",
       " 'Feedgrain',\n",
       " 'ketchup',\n",
       " 'scapegoat',\n",
       " 'AMATIL',\n",
       " 'AMAA',\n",
       " 'Merchanting',\n",
       " 'Tissue',\n",
       " 'plannned',\n",
       " 'FINNS',\n",
       " 'locating',\n",
       " 'enhancer',\n",
       " 'tetra',\n",
       " 'ethyl',\n",
       " 'Limit',\n",
       " 'FORREST',\n",
       " 'WHIM',\n",
       " 'Austwhim',\n",
       " 'Croesus',\n",
       " 'STAGNATING',\n",
       " '491p',\n",
       " '468p',\n",
       " '481p',\n",
       " 'LOSES',\n",
       " 'susbidiaries',\n",
       " 'Viviez',\n",
       " 'Padaeng',\n",
       " 'PREDICT',\n",
       " 'ANHEUSER',\n",
       " 'BUSCH',\n",
       " 'BOOMING',\n",
       " 'trillions',\n",
       " 'sloshing',\n",
       " 'attraction',\n",
       " 'unobtainable',\n",
       " 'edgy',\n",
       " 'pouring',\n",
       " 'ordinaries',\n",
       " 'Crucial',\n",
       " 'sapped',\n",
       " 'edict',\n",
       " 'petrodollar',\n",
       " 'portrayed',\n",
       " 'overstressed',\n",
       " 'REDLAND',\n",
       " 'Isuzu',\n",
       " 'refute',\n",
       " 'briefcase',\n",
       " 'BLLA',\n",
       " 'Astin',\n",
       " 'Nendick',\n",
       " 'referral',\n",
       " 'Standing',\n",
       " 'constituents',\n",
       " 'Harmoko',\n",
       " 'CIIF',\n",
       " 'rightful',\n",
       " 'motives',\n",
       " 'contravention',\n",
       " 'adversarial',\n",
       " 'exile',\n",
       " 'neighbourhood',\n",
       " 'greener',\n",
       " 'Bundaberg',\n",
       " 'FONDIARIA',\n",
       " 'LFDI',\n",
       " 'Iniziativa',\n",
       " 'Meta',\n",
       " 'INZI',\n",
       " 'DSMN',\n",
       " 'CSN',\n",
       " 'AUXTON',\n",
       " 'AUXT',\n",
       " 'CBIO',\n",
       " 'scaleup',\n",
       " 'commercialize',\n",
       " 'PALL',\n",
       " 'PLL',\n",
       " 'racket',\n",
       " 'toiletry',\n",
       " 'sait',\n",
       " 'Phone',\n",
       " 'ITEMS',\n",
       " 'formalise',\n",
       " 'preside',\n",
       " 'Flevoland',\n",
       " 'CAYUGA',\n",
       " 'CAYB',\n",
       " 'JSBK',\n",
       " 'GEODYNAMICS',\n",
       " 'GDYN',\n",
       " 'CPQ',\n",
       " 'IU',\n",
       " 'TELCOM',\n",
       " 'LEGISLATION',\n",
       " 'notifying',\n",
       " 'notificaton',\n",
       " 'tiered',\n",
       " 'insures',\n",
       " 'HELEN',\n",
       " 'TROY',\n",
       " 'HELE',\n",
       " 'higest',\n",
       " 'MEA',\n",
       " 'augurs',\n",
       " 'Burnell',\n",
       " 'unbleached',\n",
       " 'TCJC',\n",
       " '4thh',\n",
       " 'PAXAR',\n",
       " 'Lohn',\n",
       " 'BASHAW',\n",
       " 'ERSKINE',\n",
       " 'Leduc',\n",
       " 'ENTOURAGE',\n",
       " 'ENTG',\n",
       " 'soliciation',\n",
       " 'lipstick',\n",
       " 'JAX',\n",
       " 'FINISHED',\n",
       " 'Roughly',\n",
       " 'Unie',\n",
       " 'suger',\n",
       " 'CITYTRUST',\n",
       " 'CITR',\n",
       " 'NURSING',\n",
       " 'Bybee',\n",
       " 'FIRSTBANC',\n",
       " 'FBOH',\n",
       " 'NATG',\n",
       " 'Gaurd',\n",
       " 'Paramus',\n",
       " 'Investigations',\n",
       " 'Hackensack',\n",
       " 'Detective',\n",
       " 'Certified',\n",
       " 'Alarm',\n",
       " 'UMBIZ',\n",
       " 'Buildings',\n",
       " 'revoked',\n",
       " 'WEDGESTONE',\n",
       " 'WDG',\n",
       " 'shareholkders',\n",
       " 'ny',\n",
       " 'intermittently',\n",
       " 'millimetres',\n",
       " 'Deterioration',\n",
       " 'discover',\n",
       " 'experimental',\n",
       " 'Preparation',\n",
       " 'Larosiere',\n",
       " 'READER',\n",
       " 'DIGEST',\n",
       " 'Telecomputing',\n",
       " '3489',\n",
       " '5571',\n",
       " '2315',\n",
       " '2743',\n",
       " 'IVB',\n",
       " 'TRANSLATION',\n",
       " 'DATX',\n",
       " 'PETROCHEMICAL',\n",
       " 'propel',\n",
       " 'sickly',\n",
       " 'mothball',\n",
       " 'powerhouse',\n",
       " 'bucking',\n",
       " 'glamorous',\n",
       " 'Garo',\n",
       " 'FIDATA',\n",
       " 'FID',\n",
       " 'MARBLE',\n",
       " 'MRBL',\n",
       " 'DIEBOLD',\n",
       " 'DBD',\n",
       " 'unsuccesful',\n",
       " '1550',\n",
       " 'Leonardo',\n",
       " 'sacks',\n",
       " 'queues',\n",
       " 'FREER',\n",
       " 'repoprt',\n",
       " 'MONOBLOC',\n",
       " 'Monobloc',\n",
       " 'Metalurgicos',\n",
       " 'Alava',\n",
       " 'RHD',\n",
       " 'MADEIRA',\n",
       " 'CELLTRONICS',\n",
       " 'CELT',\n",
       " 'Celltronics',\n",
       " 'AGRIMONT',\n",
       " 'fertlizer',\n",
       " 'Conserv',\n",
       " 'Ettore',\n",
       " 'dell',\n",
       " 'Isola',\n",
       " 'Picco',\n",
       " 'Gianfranco',\n",
       " 'Ceroni',\n",
       " 'Olii',\n",
       " 'Sifi',\n",
       " 'Argimont',\n",
       " 'GGFH',\n",
       " 'SOUND',\n",
       " 'Alexanders',\n",
       " 'TELECRAFTER',\n",
       " 'BATON',\n",
       " 'UCT',\n",
       " 'Editions',\n",
       " 'victors',\n",
       " 'housecleaning',\n",
       " 'McKinnon',\n",
       " 'Masland',\n",
       " 'carpets',\n",
       " 'Ponderosa',\n",
       " 'Pepperell',\n",
       " 'WPM',\n",
       " 'timidity',\n",
       " 'Ashai',\n",
       " 'propsective',\n",
       " 'Darlington',\n",
       " 'Fayetteville',\n",
       " 'decribes',\n",
       " 'PARTICIPATING',\n",
       " 'MPMTS',\n",
       " 'GECL',\n",
       " 'Picker',\n",
       " '206p',\n",
       " '201p',\n",
       " 'uninsured',\n",
       " 'STANDING',\n",
       " 'DANA',\n",
       " 'DCN',\n",
       " 'Agrnomics',\n",
       " 'dlres',\n",
       " 'DJ',\n",
       " 'WIDER',\n",
       " 'PENETRATION',\n",
       " 'Freddie',\n",
       " 'hectoliters',\n",
       " 'Amstel',\n",
       " 'Aguila',\n",
       " 'regionalized',\n",
       " 'liters',\n",
       " 'rendered',\n",
       " 'Heinken',\n",
       " 'banana',\n",
       " 'Yohai',\n",
       " 'INCOMEX',\n",
       " 'mental',\n",
       " 'DIALOGUE',\n",
       " 'SOLVE',\n",
       " 'basicly',\n",
       " 'territorrial',\n",
       " 'Aart',\n",
       " 'SOUTHINGTON',\n",
       " 'SSBB',\n",
       " 'cardiac',\n",
       " 'cardiovascualr',\n",
       " 'catheters',\n",
       " 'beg',\n",
       " 'steal',\n",
       " 'recalls',\n",
       " 'Regulators',\n",
       " 'needless',\n",
       " 'overprescription',\n",
       " 'Medtronics',\n",
       " 'Activitrax',\n",
       " 'varies',\n",
       " 'heartrate',\n",
       " 'SPIE',\n",
       " 'BATIGNOLLES',\n",
       " 'poroduction',\n",
       " 'APP',\n",
       " 'TARRIFFS',\n",
       " 'Kell',\n",
       " 'Bowling',\n",
       " 'capitalizing',\n",
       " 'PUSHING',\n",
       " 'IRANIANS',\n",
       " 'Command',\n",
       " 'foiled',\n",
       " 'Guards',\n",
       " 'gunships',\n",
       " 'purge',\n",
       " 'Iraqis',\n",
       " 'Ahvaz',\n",
       " 'Colville',\n",
       " 'PILOTS',\n",
       " 'exptect',\n",
       " 'redesigned',\n",
       " 'Kuppenheimer',\n",
       " 'Briar',\n",
       " 'shirts',\n",
       " 'Obed',\n",
       " 'Asamoah',\n",
       " 'desireable',\n",
       " 'generalize',\n",
       " 'stagflation',\n",
       " 'exceedingly',\n",
       " 'RECONVENE',\n",
       " 'FAULTY',\n",
       " 'incapable',\n",
       " 'corrupt',\n",
       " 'degrade',\n",
       " 'adulterated',\n",
       " 'Accountability',\n",
       " 'flavoring',\n",
       " 'spit',\n",
       " 'chewing',\n",
       " 'gum',\n",
       " 'towels',\n",
       " 'noses',\n",
       " 'inspects',\n",
       " 'turkeys',\n",
       " 'bacterium',\n",
       " 'Salmonella',\n",
       " 'broilers',\n",
       " 'microoganisms',\n",
       " 'nutritious',\n",
       " 'Emerling',\n",
       " 'Purveyors',\n",
       " 'voids',\n",
       " 'prevention',\n",
       " 'Natiionale',\n",
       " 'discovers',\n",
       " 'cropped',\n",
       " 'amendend',\n",
       " 'glitches',\n",
       " 'visualize',\n",
       " 'AIRSENSORS',\n",
       " 'ARSN',\n",
       " 'attibuted',\n",
       " 'Guminski',\n",
       " 'Molybdenum',\n",
       " 'BANPONCE',\n",
       " 'BDEP',\n",
       " 'XEBEC',\n",
       " 'XEBC',\n",
       " 'XT',\n",
       " 'phasing',\n",
       " 'AGriculture',\n",
       " 'Donis',\n",
       " 'Jacob',\n",
       " 'Ite',\n",
       " 'BRANDED',\n",
       " 'jaw',\n",
       " 'branding',\n",
       " 'IMPORTERS',\n",
       " 'Madam',\n",
       " 'Gre',\n",
       " 'Tapie',\n",
       " 'perfumes',\n",
       " 'Gres',\n",
       " 'ARMEL',\n",
       " 'Beam',\n",
       " 'Distilling',\n",
       " 'DeKuyper',\n",
       " 'Liqueurs',\n",
       " 'Windsor',\n",
       " 'Whisky',\n",
       " 'Comserv',\n",
       " 'WOJNILOWER',\n",
       " 'subverting',\n",
       " 'Justifiably',\n",
       " 'hiccup',\n",
       " 'unsustainable',\n",
       " 'Raytech',\n",
       " 'Produkte',\n",
       " 'GmBH',\n",
       " 'Radevormwald',\n",
       " 'clutch',\n",
       " 'backdoor',\n",
       " 'V2500',\n",
       " 'MTU',\n",
       " 'WAB',\n",
       " 'baseload',\n",
       " 'powerplants',\n",
       " 'Companywide',\n",
       " 'SVU',\n",
       " 'ANDOVER',\n",
       " 'CFCF',\n",
       " 'Dartmouth',\n",
       " 'HAWKEYE',\n",
       " 'HWKB',\n",
       " 'identifed',\n",
       " 'Colson',\n",
       " 'CURE',\n",
       " 'infinitesimal',\n",
       " 'fraught',\n",
       " 'refuel',\n",
       " 'chase',\n",
       " 'strings',\n",
       " 'Kemper',\n",
       " 'perserve',\n",
       " 'joked',\n",
       " 'sleep',\n",
       " 'WSAM',\n",
       " 'etc',\n",
       " 'GBAN',\n",
       " 'Ponds',\n",
       " 'Grandad',\n",
       " 'whiskey',\n",
       " 'lecture',\n",
       " 'parted',\n",
       " 'Hence',\n",
       " 'safeguarding',\n",
       " 'sufficed',\n",
       " 'RETAINING',\n",
       " 'Bula',\n",
       " 'Seram',\n",
       " 'Shinbun',\n",
       " 'Foodstuff',\n",
       " 'SHOWA',\n",
       " 'DENKO',\n",
       " 'CASTING',\n",
       " 'athwart',\n",
       " 'potent',\n",
       " 'prowess',\n",
       " 'internationalized',\n",
       " 'outraged',\n",
       " 'prominence',\n",
       " 'nurtured',\n",
       " 'Kakuei',\n",
       " 'Recognized',\n",
       " 'bureaucrats',\n",
       " 'obstructionist',\n",
       " 'feudal',\n",
       " 'turf',\n",
       " 'sheltering',\n",
       " 'Providing',\n",
       " '91p',\n",
       " '22p',\n",
       " 'REVIVE',\n",
       " 'concretely',\n",
       " 'Pests',\n",
       " 'midges',\n",
       " 'aphids',\n",
       " 'mite',\n",
       " 'powdery',\n",
       " 'AIDING',\n",
       " 'Borax',\n",
       " 'Pillar',\n",
       " 'BRIDGESTONE',\n",
       " 'BRIT',\n",
       " 'MARKING',\n",
       " 'FAVOURABLE',\n",
       " 'GEBRUEDER',\n",
       " 'SULZER',\n",
       " 'Gebrueder',\n",
       " 'Sulzer',\n",
       " 'SULZ',\n",
       " 'PERGAMON',\n",
       " 'HOLLIS',\n",
       " 'NATIONALE',\n",
       " 'NEDERLANDEN',\n",
       " 'NTNN',\n",
       " 'TYREb',\n",
       " 'radial',\n",
       " 'CAUGHT',\n",
       " '7507',\n",
       " 'Sennen',\n",
       " 'para',\n",
       " 'inserting',\n",
       " 'Trengganu',\n",
       " 'Johor',\n",
       " 'appraising',\n",
       " 'Utilisation',\n",
       " 'Kertih',\n",
       " 'CCFP',\n",
       " 'Socialists',\n",
       " 'Sogenal',\n",
       " 'unfabricated',\n",
       " 'parentheses',\n",
       " 'PALLADIUM',\n",
       " 'IRIDIUM',\n",
       " 'RHODIUM',\n",
       " 'RUTHENIUM',\n",
       " 'LEX',\n",
       " 'LEXL',\n",
       " 'SEHL',\n",
       " '400p',\n",
       " 'Concessionaires',\n",
       " '409p',\n",
       " '419p',\n",
       " 'OLDHAM',\n",
       " 'comminuique',\n",
       " 'NATNED',\n",
       " 'NTTN',\n",
       " 'Claim',\n",
       " 'payouts',\n",
       " 'aft',\n",
       " 'INTERRUPTED',\n",
       " 'timescale',\n",
       " 'Alois',\n",
       " 'Schwietert',\n",
       " 'subtracting',\n",
       " 'exlude',\n",
       " 'CHIPS',\n",
       " 'Annuities',\n",
       " 'differently',\n",
       " 'Insurer',\n",
       " 'RESOLVE',\n",
       " 'pin',\n",
       " 'justed',\n",
       " 'adoped',\n",
       " 'squared',\n",
       " '?,\"',\n",
       " 'UNIFIRST',\n",
       " 'UNF',\n",
       " 'Unseasonal',\n",
       " 'Rhineland',\n",
       " 'SAVER',\n",
       " 'CODA',\n",
       " 'EXERCISED',\n",
       " 'CSA',\n",
       " 'BRAMALL',\n",
       " '265p',\n",
       " '278p',\n",
       " 'mananger',\n",
       " 'unevenly',\n",
       " 'XICOR',\n",
       " 'XICO',\n",
       " 'Telkom',\n",
       " 'DATATRAK',\n",
       " 'DTRK',\n",
       " 'STRUCK',\n",
       " 'balloting',\n",
       " 'tabulated',\n",
       " 'NAtional',\n",
       " 'CABK',\n",
       " 'Bran',\n",
       " 'pollard',\n",
       " 'AUCTIONED',\n",
       " 'LINIERS',\n",
       " 'MAXIMUN',\n",
       " 'AUSTRALES',\n",
       " 'KILO',\n",
       " 'BRACKETS',\n",
       " 'INCLUDED',\n",
       " 'COWS',\n",
       " 'CANNING',\n",
       " 'PHYSIO',\n",
       " 'PHYT',\n",
       " 'dealter',\n",
       " 'washington',\n",
       " 'followthrough',\n",
       " 'REMOVED',\n",
       " 'Moderately',\n",
       " 'Aqaba',\n",
       " 'Pallice',\n",
       " 'reappeared',\n",
       " 'Savona',\n",
       " 'CASCAVEL',\n",
       " 'PONTA',\n",
       " 'GROSSA',\n",
       " 'CAMPO',\n",
       " 'MOURAO',\n",
       " 'GRANDO',\n",
       " 'SUL',\n",
       " 'PASSO',\n",
       " 'FUNDO',\n",
       " 'MARIA',\n",
       " 'CRUZ',\n",
       " 'ALTA',\n",
       " 'LUIZ',\n",
       " 'GONZAGA',\n",
       " 'Ronnie',\n",
       " 'separatist',\n",
       " 'GEMINA',\n",
       " 'AMBROSIANO',\n",
       " 'Nuovo',\n",
       " 'Bazoli',\n",
       " 'WHR',\n",
       " 'endorses',\n",
       " 'bickering',\n",
       " 'reafffirmation',\n",
       " 'blunts',\n",
       " 'monolith',\n",
       " 'mounds',\n",
       " 'wealthier',\n",
       " 'Debtor',\n",
       " 'feeble',\n",
       " 'examines',\n",
       " 'curious',\n",
       " 'resonably',\n",
       " 'heeding',\n",
       " 'FINELY',\n",
       " 'BALANCED',\n",
       " 'PHYSICALS',\n",
       " 'Delayed',\n",
       " 'Linares',\n",
       " 'Trieste',\n",
       " 'Warehouses',\n",
       " 'Weapons',\n",
       " 'Test',\n",
       " 'Surfside',\n",
       " 'SURPRISED',\n",
       " 'depository',\n",
       " 'FOODGRAIN',\n",
       " 'meterological',\n",
       " 'millets',\n",
       " 'resilience',\n",
       " 'varieites',\n",
       " 'Simultaneously',\n",
       " 'vigrously',\n",
       " 'unsolicted',\n",
       " 'hundreth',\n",
       " 'ammount',\n",
       " 'ZENEX',\n",
       " 'Truscott',\n",
       " 'TEMPERATURES',\n",
       " 'CENTIGRADE',\n",
       " '...............',\n",
       " 'MAX',\n",
       " 'MIN',\n",
       " 'BUENOS',\n",
       " 'AIRES',\n",
       " 'BLANCA',\n",
       " 'ARROYOS',\n",
       " 'TANDIL',\n",
       " '.............',\n",
       " 'JUNIN',\n",
       " 'ROSA',\n",
       " '.........--........',\n",
       " 'CORDOBA',\n",
       " 'auditing',\n",
       " 'erased',\n",
       " 'faked',\n",
       " 'Burkhard',\n",
       " 'Junger',\n",
       " 'evaded',\n",
       " 'NAIROBI',\n",
       " 'KG',\n",
       " '2304',\n",
       " '2267',\n",
       " '7289',\n",
       " '6834',\n",
       " '2292',\n",
       " '2358',\n",
       " '12664',\n",
       " '11895',\n",
       " '2289',\n",
       " '2291',\n",
       " '3198',\n",
       " '2867',\n",
       " '2073',\n",
       " '2107',\n",
       " '1508',\n",
       " '1510',\n",
       " 'TT',\n",
       " '2053',\n",
       " '2095',\n",
       " '2250',\n",
       " '2252',\n",
       " 'MISC',\n",
       " '9009',\n",
       " '8440',\n",
       " '1409',\n",
       " '1398',\n",
       " '35000',\n",
       " '32876',\n",
       " '2014',\n",
       " 'HIGHLAND',\n",
       " 'SUPERSTORES',\n",
       " 'BRENDA',\n",
       " 'KERR',\n",
       " 'ADDISON',\n",
       " 'Brenda',\n",
       " 'Addison',\n",
       " 'PHFC',\n",
       " 'Ackerman',\n",
       " 'initital',\n",
       " 'TROW',\n",
       " 'HERS',\n",
       " 'downsize',\n",
       " 'revenueslast',\n",
       " 'STRATHFIELD',\n",
       " 'SALT',\n",
       " 'Packet',\n",
       " 'cornering',\n",
       " 'AFBD',\n",
       " 'prepackers',\n",
       " 'CANAM',\n",
       " 'MANAC',\n",
       " 'kerb',\n",
       " 'LACKLUSTRE',\n",
       " '8365',\n",
       " 'Bundebank',\n",
       " 'Euromark',\n",
       " 'unaltered',\n",
       " '2570',\n",
       " '2515',\n",
       " 'CPER',\n",
       " 'Primedical',\n",
       " 'COIL',\n",
       " 'METS',\n",
       " 'dive',\n",
       " 'modernizing',\n",
       " 'slimmed',\n",
       " 'recouped',\n",
       " 'Michelle',\n",
       " 'Galanter',\n",
       " 'dropoff',\n",
       " 'positives',\n",
       " 'SDhr',\n",
       " 'WEAKER',\n",
       " 'nutritional',\n",
       " 'DISTRIBUTIVE',\n",
       " 'tenderloins',\n",
       " 'steaks',\n",
       " '167a',\n",
       " 'peeled',\n",
       " 'gooseneck',\n",
       " 'rnd',\n",
       " 'lint',\n",
       " 'gins',\n",
       " 'SHIFTS',\n",
       " 'ORDERLY',\n",
       " 'crafting',\n",
       " 'conditionality',\n",
       " 'CFF',\n",
       " 'Forms',\n",
       " 'MSE',\n",
       " 'KINARK',\n",
       " 'KIN',\n",
       " 'Falkenstein',\n",
       " 'Kinark',\n",
       " 'ORANGES',\n",
       " 'breadmaking',\n",
       " 'WRII',\n",
       " 'BNCH',\n",
       " '99ct',\n",
       " 'cxts',\n",
       " 'KURZ',\n",
       " 'KASCH',\n",
       " 'COMPONENT',\n",
       " 'CTEC',\n",
       " 'Kurz',\n",
       " 'Kasch',\n",
       " 'thermoset',\n",
       " 'immature',\n",
       " 'localized',\n",
       " 'OFFSETTING',\n",
       " 'restruction',\n",
       " 'NOTION',\n",
       " 'NEARER',\n",
       " 'STUDENT',\n",
       " 'LYLE',\n",
       " 'JETTY',\n",
       " 'UNLOADING',\n",
       " 'Lyles',\n",
       " 'weighhouse',\n",
       " 'Maputo',\n",
       " 'Psarouthakis',\n",
       " 'MTRUS',\n",
       " 'ulcer',\n",
       " 'Cytotech',\n",
       " 'ulcers',\n",
       " 'GAME',\n",
       " 'STGM',\n",
       " 'UFC',\n",
       " 'NORTHWESTERN',\n",
       " 'NWNL',\n",
       " 'SIERRITA',\n",
       " 'fron',\n",
       " 'Hartselle',\n",
       " 'FAB',\n",
       " 'FIT',\n",
       " 'AUTHORISED',\n",
       " 'colombian',\n",
       " 'Vamand',\n",
       " 'Cory',\n",
       " 'Prai',\n",
       " 'Inchon',\n",
       " 'Reunion',\n",
       " 'daps',\n",
       " 'Guanta',\n",
       " 'Naantali',\n",
       " 'compute',\n",
       " 'WTAF',\n",
       " 'WDCA',\n",
       " 'WCIX',\n",
       " 'KTXA',\n",
       " 'KTXH',\n",
       " 'EASTER',\n",
       " 'occurance',\n",
       " 'housewares',\n",
       " 'signaling',\n",
       " 'nears',\n",
       " 'Mackes',\n",
       " 'promotions',\n",
       " 'CJ',\n",
       " 'SOYOIL',\n",
       " 'FITCHBURG',\n",
       " 'FGE',\n",
       " 'corroding',\n",
       " 'Mayaguez',\n",
       " 'PROTECTIVE',\n",
       " 'PROT',\n",
       " 'CBAN',\n",
       " 'EMCOR',\n",
       " 'Emcore',\n",
       " 'Concord',\n",
       " 'JEOPARDY',\n",
       " 'clamping',\n",
       " 'erecting',\n",
       " 'fences',\n",
       " 'Shawmut',\n",
       " 'Minntech',\n",
       " 'membrane',\n",
       " 'oxygenator',\n",
       " 'filtration',\n",
       " 'Cosentino',\n",
       " 'Pritzker',\n",
       " 'Pritzkers',\n",
       " 'SLAT',\n",
       " 'SJI',\n",
       " 'ABGA',\n",
       " 'brightened',\n",
       " 'underscoring',\n",
       " 'Doherty',\n",
       " 'Nonaccrual',\n",
       " '3267',\n",
       " 'highlights',\n",
       " 'crushings',\n",
       " 'POTATOES',\n",
       " 'inview',\n",
       " 'Soy',\n",
       " 'Ultimate',\n",
       " 'Exporter',\n",
       " 'Accumulated',\n",
       " 'Indicated',\n",
       " 'bulgur',\n",
       " 'farina',\n",
       " 'cracked',\n",
       " 'COTTONSEED',\n",
       " 'Expt',\n",
       " 'denotes',\n",
       " 'WestHem',\n",
       " 'Yld',\n",
       " 'thous',\n",
       " 'Rough',\n",
       " 'TABLES',\n",
       " 'BEVERAGES',\n",
       " 'FNNI',\n",
       " 'FCOLA',\n",
       " 'comapny',\n",
       " 'UHT',\n",
       " 'Telkon',\n",
       " 'ISSUED',\n",
       " 'Produc',\n",
       " 'Coarse',\n",
       " 'Bales',\n",
       " 'Milled',\n",
       " 'Basis',\n",
       " 'lastest',\n",
       " 'Maione',\n",
       " 'sony',\n",
       " 'WNN',\n",
       " 'Winn',\n",
       " 'Shasta',\n",
       " 'Spree',\n",
       " 'ramp',\n",
       " 'Provincial',\n",
       " 'NR',\n",
       " 'surpasssing',\n",
       " 'distortive',\n",
       " 'abatements',\n",
       " 'dilulted',\n",
       " 'FUNDAMENTAL',\n",
       " 'facilitated',\n",
       " 'effiency',\n",
       " 'Chartham',\n",
       " 'SEALY',\n",
       " 'LLX',\n",
       " 'TRACTS',\n",
       " 'Oranje',\n",
       " 'Energie',\n",
       " 'Q4a',\n",
       " 'E12c',\n",
       " 'E15b',\n",
       " 'Q5c',\n",
       " 'Sixth',\n",
       " 'BOMA',\n",
       " 'Frampton',\n",
       " 'GWAY',\n",
       " 'BAKR',\n",
       " 'EASTOVER',\n",
       " 'EASTS',\n",
       " 'unposted',\n",
       " 'BEVI',\n",
       " 'INQUIRIES',\n",
       " 'Pneumatics',\n",
       " 'JACOR',\n",
       " 'JCOR',\n",
       " 'DENVER',\n",
       " 'Belo',\n",
       " 'KOA',\n",
       " 'KOAQ',\n",
       " 'POLYCAST',\n",
       " 'PTCC',\n",
       " 'relected',\n",
       " 'Attaka',\n",
       " 'compass',\n",
       " 'indentifying',\n",
       " 'NERCI',\n",
       " 'doubles',\n",
       " 'PROPEL',\n",
       " 'kindled',\n",
       " 'tedious',\n",
       " 'Marty',\n",
       " 'McNeill',\n",
       " 'reverberated',\n",
       " 'TRUSTCORP',\n",
       " 'TTCO',\n",
       " 'NVBC',\n",
       " 'PWR',\n",
       " 'MGMT',\n",
       " 'MCL',\n",
       " 'Judson',\n",
       " 'expediency',\n",
       " 'DCF',\n",
       " 'Schloss',\n",
       " 'DELMED',\n",
       " 'DMD',\n",
       " 'WINTERHALTER',\n",
       " 'WNTLC',\n",
       " 'Interface',\n",
       " 'INTF',\n",
       " 'DOUBT',\n",
       " 'FIRMED',\n",
       " 'borrrowings',\n",
       " 'catchup',\n",
       " 'arrranged',\n",
       " 'VALEX',\n",
       " 'VALP',\n",
       " '8155',\n",
       " '8187',\n",
       " 'surpised',\n",
       " '5120',\n",
       " '5085',\n",
       " '6190',\n",
       " '6195',\n",
       " 'Constitucion',\n",
       " 'Alvear',\n",
       " 'Millet',\n",
       " 'GLIMPSE',\n",
       " 'NIGHTMARE',\n",
       " 'scare',\n",
       " '2339',\n",
       " 'nightmare',\n",
       " 'agony',\n",
       " 'teaches',\n",
       " 'Reflected',\n",
       " 'scoffed',\n",
       " 'helmets',\n",
       " 'markest',\n",
       " 'Hurting',\n",
       " 'ACTU',\n",
       " 'paralyse',\n",
       " 'Temuco',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the words that only appear once (these words are called hap\n",
    "fdist.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41600\n"
     ]
    }
   ],
   "source": [
    "# Hapaxes usually are `mispeled` or weirdly `cApiTALIZED` words.\n",
    "# Total number of distinct words\n",
    "print(len(fdist.keys())) # 41600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720901\n"
     ]
    }
   ],
   "source": [
    "# Total number of samples\n",
    "print(fdist.N()) # 1720901"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun with Bigrams and Trigrams\n",
    "You’ll hear about bigrams and trigrams a lot in NLP. **There are nothing but pairs or\n",
    "triplets of adjacent words.** If we would generalize the term to bigger lengths, we get\n",
    "ngrams.\n",
    "\n",
    "Ngrams are used to build approximate language models, but they are also used in\n",
    "text classification tasks or as features for various other natural language statistical\n",
    "models. Bigrams and trigrams are especially popular because usually going further\n",
    "in size, you don’t get any significant performance boost but rather a more complex\n",
    "model. Here are some shortcuts to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting bigrams & trigrams\n",
    "from nltk import bigrams, trigrams, word_tokenize\n",
    "text = \"John works at Intel.\"\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'works'), ('works', 'at'), ('at', 'Intel'), ('Intel', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(bigrams(tokens))) # the `bigrams` function returns a generator, so we must unwind it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'works', 'at'), ('works', 'at', 'Intel'), ('at', 'Intel', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(trigrams(tokens))) # the `trigrams` function returns a generator, so we must unwind it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A particular subset of a texts bigrams/trigrams are the collocations. To better\n",
    "understand what the collocations are, you can think of them like an expression\n",
    "of multiple words which commonly co-occur. Collocations can tell us a lot about\n",
    "the text they are extracted from and can be used as important features in different\n",
    "tasks.\n",
    "Here’s how to compute them using some handy NLTK functions:\n",
    "\n",
    "**Extracting collocations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder\n",
    "bigram_measures = BigramAssocMeasures()\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute length-2 collocations\n",
    "finder = BigramCollocationFinder.from_words(nltk.corpus.reuters.words())\n",
    "\n",
    "# only bigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DU', 'PONT'),\n",
       " ('Keng', 'Yaik'),\n",
       " ('Kwik', 'Save'),\n",
       " ('Nihon', 'Keizai'),\n",
       " ('corenes', 'pora'),\n",
       " ('fluidized', 'bed'),\n",
       " ('Akbar', 'Hashemi'),\n",
       " ('Constructions', 'Telephoniques'),\n",
       " ('Elevator', 'Mij'),\n",
       " ('Entre', 'Rios'),\n",
       " ('Graan', 'Elevator'),\n",
       " ('JIM', 'WALTER'),\n",
       " ('Taikoo', 'Shing'),\n",
       " ('der', 'Vorm'),\n",
       " ('di', 'Clemente'),\n",
       " ('Borrowing', 'Requirement'),\n",
       " ('FOOTE', 'MINERAL'),\n",
       " ('Hawker', 'Siddeley'),\n",
       " ('JARDINE', 'MATHESON'),\n",
       " ('PRORATION', 'FACTOR'),\n",
       " ('Wildlife', 'Refuge'),\n",
       " ('Kohlberg', 'Kravis'),\n",
       " ('Almir', 'Pazzionotto'),\n",
       " ('Bankhaus', 'Centrale'),\n",
       " ('Corpus', 'Christi'),\n",
       " ('Kuala', 'Lumpur'),\n",
       " ('Maple', 'Leaf'),\n",
       " ('Stats', 'Oljeselskap'),\n",
       " ('Zoete', 'Wedd'),\n",
       " ('Tadashi', 'Kuranari'),\n",
       " ('Drawing', 'Rights'),\n",
       " ('EASTMAN', 'KODAK'),\n",
       " ('Martinez', 'Cuenca'),\n",
       " ('Mathematical', 'Applications'),\n",
       " ('Neutral', 'Zone'),\n",
       " ('Townsend', 'Thoresen'),\n",
       " ('Sector', 'Borrowing'),\n",
       " ('Hashemi', 'Rafsanjani'),\n",
       " ('Hossein', 'Mousavi'),\n",
       " ('Kitty', 'Hawk'),\n",
       " ('Task', 'Force'),\n",
       " ('Tender', 'Loving'),\n",
       " ('WELLS', 'FARGO'),\n",
       " ('SLAUGHTER', 'GUESSTIMATES'),\n",
       " ('ad', 'hoc'),\n",
       " ('mechanically', 'separated'),\n",
       " ('bleached', 'deodorised'),\n",
       " ('Alejandro', 'Martinez'),\n",
       " ('Salina', 'Cruz'),\n",
       " ('Het', 'Comite')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the 50 bigrams with the highest PMI (Pointwise Mutual Information)\n",
    "finder.nbest(bigram_measures.pmi, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# among the collocations we can find stuff like: (u'Corpus', u'Christi') ...\n",
    "# Compute length-3 collocations\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(nltk.corpus.reuters.words())\n",
    "# only trigrams that appear 5+ times\n",
    "finder.apply_freq_filter(5)\n",
    "# return the 50 trigrams with the highest PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Graan', 'Elevator', 'Mij'),\n",
       " ('Sector', 'Borrowing', 'Requirement'),\n",
       " ('Akbar', 'Hashemi', 'Rafsanjani'),\n",
       " ('Lim', 'Keng', 'Yaik'),\n",
       " ('Alejandro', 'Martinez', 'Cuenca'),\n",
       " ('Den', 'Norske', 'Stats'),\n",
       " ('Norske', 'Stats', 'Oljeselskap'),\n",
       " ('Kokusai', 'Denshin', 'Denwa'),\n",
       " ('Special', 'Drawing', 'Rights'),\n",
       " ('Dar', 'es', 'Salaam'),\n",
       " ('FOLLOWING', 'RAINFALL', 'WAS'),\n",
       " ('Duffour', 'et', 'Igon'),\n",
       " ('Tender', 'Loving', 'Care'),\n",
       " ('CATTLE', 'SLAUGHTER', 'GUESSTIMATES'),\n",
       " ('CAMPBELL', 'RED', 'LAKE'),\n",
       " ('Victor', 'Paz', 'Estenssoro'),\n",
       " ('Carter', 'Hawley', 'Hale'),\n",
       " ('Punta', 'del', 'Este'),\n",
       " ('ELEVATOR', 'LOADING', 'WAITING'),\n",
       " ('TIME', 'JOBLESS', 'CLAIMS'),\n",
       " ('Francaise', 'des', 'Petroles'),\n",
       " ('Public', 'Sector', 'Borrowing'),\n",
       " ('Arturo', 'Hernandez', 'Grisanti'),\n",
       " ('Speaker', 'Jim', 'Wright'),\n",
       " ('carrier', 'Kitty', 'Hawk'),\n",
       " ('Archer', 'Daniels', 'Midland'),\n",
       " ('Corning', 'Glass', 'Works'),\n",
       " ('refined', 'bleached', 'deodorised'),\n",
       " ('Grown', 'Cereals', 'Authority'),\n",
       " ('Commissioner', 'Frans', 'Andriessen'),\n",
       " ('RBD', 'PALM', 'OLEIN'),\n",
       " ('RAINFALL', 'THE', 'FOLLOWING'),\n",
       " ('THE', 'FOLLOWING', 'RAINFALL'),\n",
       " ('Kremlin', 'leader', 'Mikhail'),\n",
       " ('Bankhaus', 'Centrale', 'Credit'),\n",
       " ('SANTA', 'FE', 'SOUTHERN'),\n",
       " ('Director', 'Kobena', 'Erbynn'),\n",
       " ('THOUS', 'BUSHELS', 'SOYBEANS'),\n",
       " ('GETS', 'QUALIFIED', 'AUDIT'),\n",
       " ('Denis', 'Bra', 'Kanon'),\n",
       " ('GHANA', 'COCOA', 'PURCHASES'),\n",
       " ('bleached', 'deodorised', 'palm'),\n",
       " ('leader', 'Mikhail', 'Gorbachev'),\n",
       " ('SLAUGHTER', 'GUESSTIMATES', 'Chicago'),\n",
       " ('de', 'Constructions', 'Telephoniques'),\n",
       " ('DISCOUNT', 'WINDOW', 'BORROWINGS'),\n",
       " ('Nil', 'Nil', 'Nil'),\n",
       " ('Fichtel', 'und', 'Sachs'),\n",
       " ('de', 'Zoete', 'Wedd'),\n",
       " ('Home', 'Grown', 'Cereals')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.nbest(trigram_measures.pmi, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Mutal Information\n",
    "PMI is a measure that indicates theassociation betweent tow variables\n",
    "- *how likey is that these tow values appear together?*\n",
    "\n",
    "$$\n",
    "pmi(x,y) = log\\bigg(\\frac{p(x,y)}{p(x)p(y)}\\bigg)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Of Speech Tagging\n",
    "Part of Speech Tagging (or POS Tagging, for short) is probably the most popular challenge\n",
    "in the history of NLP. POS Tagging basically implies assigning a grammatical\n",
    "label to every word in a sequence (usually a sentence). When I say grammatical\n",
    "label, I mean: Noun, Verb, Preposition, Pronoun, etc.\n",
    "\n",
    "\n",
    "In NLP, a collection of such labels is called a tag set. The most widespread one is:\n",
    "Penn Treebank Tag Set3. Below is the alphabetical list of part-of-speech tags used in\n",
    "the Penn Treebank Project\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/JvvGtXf.png)\n",
    "![](https://i.imgur.com/VssomxH.png)\n",
    "\n",
    "\n",
    "\n",
    "Your instinct now might be to run to your high school grammar book but don’t\n",
    "worry, you don’t really need to know what all those POS tags mean. In fact, not even\n",
    "all corpora implement this exact tag set, but rather a subset of it. For example, I’ve\n",
    "never encountered the LS (list item marker) or the PDT (predeterminer) anywhere.\n",
    "\n",
    "Part-Of-Speech tagging also serves as a base of deeper NLP analyses. There are just\n",
    "a few cases when you’ll work directly with the tagged sentence. A scenario that\n",
    "comes to mind is keyword extraction, when usually you only want to extract the\n",
    "adjectives and nouns. In this case, you use the tags to filter out those words that\n",
    "can’t be a keyword.\n",
    "\n",
    "If you’re not familiar with the task, nowadays, POS tagging is done with machine\n",
    "learning models. But a while ago, POS taggers we’re rule-based. Using regular\n",
    "expressions and various heuristics, the POS tagger would determine an appropriate tag.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem like a rather massive oversimplification, but this is the general idea.\n",
    "The challenge was to come up with rules that best described the phenomena that is\n",
    "the human language. But, as you go deeper and deeper, the rules become more and\n",
    "more complex, getting harder to keep track with which rules did what, if there were\n",
    "rules that were contradicting one another etc. Moreover, humans don’t usually\n",
    "excel at noticing correlations between a great number of variables. In this case,\n",
    "the variables could have been\n",
    "\n",
    "\n",
    "- Previous words\n",
    "- Following words\n",
    "- Prefixes, Suffixes\n",
    "- Previous POS tags\n",
    "- Word capitalization\n",
    "\n",
    "\n",
    "\n",
    "Mathematical algorithms are better at estimating which are the optimum rules\n",
    "for correctly tagging words. Thus, the field turned to machine learning and the\n",
    "approach became something like this:\n",
    "\n",
    "---\n",
    "\n",
    "1. Get some humans to annotate some texts with POS tags (we’ll call this the gold\n",
    "standard)\n",
    "2. Get other humans to build some mathematical models to predict tags using a\n",
    "large part of the gold standard corpus (this is called training the model)\n",
    "3. Using the remaining part of the gold standard corpus, assess how well the\n",
    "model is performing on data the model hasn’t seen yet (this is called testing\n",
    "the model)\n",
    "\n",
    "\n",
    "This may seem complicated, and it usually is presented as such, but throughout this\n",
    "book, we’ll be demistifying all of these algorithms. To start doing POS tagging we\n",
    "don’t need much because NLTK comes with some pre-trained POS tagger models.\n",
    "It’s super easy to get started and here’s how:\n",
    "\n",
    "\n",
    "**Introducing nltk.pos_tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentence = \"Things I wish I knew before I started blogging.\"\n",
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['Things', 'I', 'wish', 'I', 'knew', 'before', 'I', 'started', 'blogging', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens: \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tagged Tokens: ',\n",
       " [('Things', 'NNS'),\n",
       "  ('I', 'PRP'),\n",
       "  ('wish', 'VBP'),\n",
       "  ('I', 'PRP'),\n",
       "  ('knew', 'VBD'),\n",
       "  ('before', 'IN'),\n",
       "  ('I', 'PRP'),\n",
       "  ('started', 'VBD'),\n",
       "  ('blogging', 'VBG'),\n",
       "  ('.', '.')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "\"Tagged Tokens: \", tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is as straight-forward and easy as this, but keep in mind that the NLTK trained\n",
    "model is not the best. It’s a bit slow and not the most precise. It is well suited though\n",
    "for doing toy projects or prototyping.\n",
    "\n",
    "## Named Entity Recognition\n",
    "\n",
    "Named Entity Recognition (NER for short) is almost as well-known and studied as\n",
    "POS tagging. NER implies extracting named entities and their classes from a given\n",
    "text. The usual named entities we’re dealing with stand for: *People, Organizations,\n",
    "Locations, Events, etc*. Sometimes, things like currencies, numbers, percents, dates\n",
    "and time expressions can be considered named entities even though they technically\n",
    "aren’t. The entities are used in information extraction tasks and usually, these\n",
    "entities can be attributed to a real-life object or concept. To make things clearer, let\n",
    "me give you some examples:\n",
    "\n",
    "- if we extract a name of a person from a text, we can associate it with a Facebook\n",
    "profile, email address or even a unique identification number\n",
    "- if we extract a date/time, we can associate the string with an actual slot in a\n",
    "calendar.\n",
    "- if we extract a location, we can associate it with some exact coordinates in\n",
    "Google Maps.\n",
    "\n",
    "**Using the nltk.ne_chunk function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Adapted from Wikipedia:\n",
    "# https://en.wikipedia.org/wiki/Surely_You%27re_Joking,_Mr._Feynman!\n",
    "sentence = \"\"\"The closing chapter, is adapted from the address that\n",
    "Feynman gave during the 1974 commencement exercises\n",
    "at the California Institute Of Technology. \"\"\"\n",
    "\n",
    "# tokenize and pos tag\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "ner_annotated_tree = nltk.ne_chunk(tagged_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closing chapter, is adapted from the address that\n",
      "Feynman gave during the 1974 commencement exercises\n",
      "at the California Institute Of Technology. \n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  closing/NN\n",
      "  chapter/NN\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  adapted/VBN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  address/NN\n",
      "  that/IN\n",
      "  (PERSON Feynman/NNP)\n",
      "  gave/VBD\n",
      "  during/IN\n",
      "  the/DT\n",
      "  1974/CD\n",
      "  commencement/NN\n",
      "  exercises/NNS\n",
      "  at/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION California/NNP Institute/NNP Of/IN Technology/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(ner_annotated_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the result has a single or multiple tokens bundled up in entities:\n",
    "1. Feynman = PERSON\n",
    "\n",
    "\n",
    "2. California Institute Of Technology = ORGANIZATION\n",
    "\n",
    "Also notice that we needed to POS tag the sentence first before feeding it to the\n",
    "`ne_chunk` function. This is because the function uses the POS tags as features that\n",
    "contribute decisively to predicting whether something is an entity or not. The most\n",
    "accessible examples are the tags `NNP` and `NNPS`. What do you think is the reason these\n",
    "tags help the NE extractor find entities?\n",
    "Let’s pay a closer look at the `ne_chunk` function. Chunking means taking the tokens\n",
    "of a sentence and grouping them together, in chunks. In this case, we grouped the\n",
    "tokens belonging to the same named entity into a single chunk. The data structure\n",
    "that facilitates this is `nltk.Tree`. The tokens of a chunk are all children of the same\n",
    "node. All the other non-entity nodes and the chunk nodes are children of the same\n",
    "root node: `S`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
