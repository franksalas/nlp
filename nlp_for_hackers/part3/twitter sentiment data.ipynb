{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Data\n",
    "Twitter is one of the most open platforms and that makes it a perfect fit for\n",
    "analyzing text from different perspectives. Twitter has been used for predicting\n",
    "election results, reputation management, brand monitoring, customer support,\n",
    "various bots, etc.\n",
    "\n",
    "## Twitter Corpora\n",
    "Twitter has been noticed in the academic environment for a while now, and various\n",
    "corpora from tweets have been created. Here are some of them:\n",
    "\n",
    "- nltk.corpus.twitter_samples - Sentiment annotated tweets -\n",
    "- Twitter Airline Reviews17\n",
    "- First GOP Debate Twitter Sentiment18\n",
    "- Sanders Analytics Twitter Sentiment Corpus19 - 5513 hand-classified tweets\n",
    "- OSU Twitter NLP Tools20 - Contains POS, Chunk and NER annotated tweets\n",
    "- Tweebank21 - Twitter CoNLL-like annotated data\n",
    "\n",
    "## Other Sentiment Analysis Corpora\n",
    "Besides the ones stated so far, there is a multitude of other corpora related to\n",
    "sentiment analysis and I am going to list some of the most well-known:\n",
    "\n",
    "- Sentiment Annotated 50.000 IMDB movie reviews22\n",
    "- Amazon Fine Food Reviews23\n",
    "- Multi-Domain Sentiment Dataset24\n",
    "- UMICH SI650 - Sentiment Classification on Kaggle25\n",
    "- SentiWordnet: Sentiment Polarities for Wordnet26\n",
    "- Miscellaneous Opinion annotated datasets27\n",
    "\n",
    "\n",
    "## Building a Tweets Dataset\n",
    "\n",
    "Let’s start by gathering the Twitter data and putting it all together. We are going to\n",
    "use three out of the six resources I have mentioned earlier in the Twitter Corpora\n",
    "chapter: NLTK Twitter Samples, Twitter Airline Reviews and First GOP Debate\n",
    "Twitter Sentiment.\n",
    "\n",
    "**Indexing NLTK Twitter Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a dataframe for storing tweets\n",
    "df = pd.DataFrame(columns=['tweet', 'source', 'sentiment'])\n",
    "\n",
    "####################################\n",
    "#\n",
    "# NLTK Twitter Samples\n",
    "#\n",
    "####################################\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "# Add the positive tweets\n",
    "for tweet in twitter_samples.strings('positive_tweets.json'):\n",
    "    df.loc[len(df)] = [tweet, 'nltk.corpus.twitter_samples', 'positive']\n",
    "\n",
    "for tweet in twitter_samples.strings('negative_tweets.json'):\n",
    "    df.loc[len(df)] = [tweet, 'nltk.corpus.twitter_samples', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>source</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2  @DespiteOfficial we had a listen last night :)...   \n",
       "3                               @97sides CONGRATS :)   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "\n",
       "                        source sentiment  \n",
       "0  nltk.corpus.twitter_samples  positive  \n",
       "1  nltk.corpus.twitter_samples  positive  \n",
       "2  nltk.corpus.twitter_samples  positive  \n",
       "3  nltk.corpus.twitter_samples  positive  \n",
       "4  nltk.corpus.twitter_samples  positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next step, you need to download the Twitter Airline Reviews corpus from\n",
    "Kaggle: https://www.kaggle.com/crowdflower/twitter-airline-sentiment28\n",
    "\n",
    "**Indexing Twitter Airline Reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#\n",
    "# Twitter Airline Reviews\n",
    "#\n",
    "####################################\n",
    "airline_tweets = pd.read_csv('data/Tweets.csv')\n",
    "# Select only the columns of interest\n",
    "airline_df = airline_tweets[['text', 'airline_sentiment']]\n",
    "# Rename the columns to fit the header\n",
    "airline_df = airline_df.rename(columns={'text': 'tweet', 'airline_sentiment': 'sentiment'})\n",
    "# Add a constant column as the source\n",
    "airline_df['source'] = 'https://www.kaggle.com/crowdflower/twitter-airline-sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/twitter-air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/twitter-air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/twitter-air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/twitter-air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/twitter-air...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.   neutral   \n",
       "1  @VirginAmerica plus you've added commercials t...  positive   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   neutral   \n",
       "3  @VirginAmerica it's really aggressive to blast...  negative   \n",
       "4  @VirginAmerica and it's a really big bad thing...  negative   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.kaggle.com/crowdflower/twitter-air...  \n",
       "1  https://www.kaggle.com/crowdflower/twitter-air...  \n",
       "2  https://www.kaggle.com/crowdflower/twitter-air...  \n",
       "3  https://www.kaggle.com/crowdflower/twitter-air...  \n",
       "4  https://www.kaggle.com/crowdflower/twitter-air...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s download the First GOP Debate Twitter Sentiment corpus from Kaggle and\n",
    "process it as well: https://www.kaggle.com/crowdflower/first-gop-debate-twittersentiment29\n",
    "\n",
    "**Indexing First GOP Debate Twitter Sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "#\n",
    "# First GOP Debate Twitter Sentiment\n",
    "#\n",
    "####################################\n",
    "debate_tweets = pd.read_csv('data/Sentiment.csv')\n",
    "# Select only the columns of interest\n",
    "debate_df = debate_tweets[['text', 'sentiment']]\n",
    "# Rename the columns to fit the header\n",
    "debate_df = debate_df.rename(columns={'text': 'tweet'})\n",
    "# Standardize the sentiment column\n",
    "debate_df['sentiment'] = debate_df['sentiment'].apply(lambda s: s.lower())\n",
    "# Add a constant column as the source\n",
    "debate_df['source'] = 'https://www.kaggle.com/crowdflower/first-gop-debate-twitter-sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/first-gop-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/first-gop-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/first-gop-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/first-gop-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>positive</td>\n",
       "      <td>https://www.kaggle.com/crowdflower/first-gop-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...   neutral   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...  positive   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...   neutral   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...  positive   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  positive   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.kaggle.com/crowdflower/first-gop-d...  \n",
       "1  https://www.kaggle.com/crowdflower/first-gop-d...  \n",
       "2  https://www.kaggle.com/crowdflower/first-gop-d...  \n",
       "3  https://www.kaggle.com/crowdflower/first-gop-d...  \n",
       "4  https://www.kaggle.com/crowdflower/first-gop-d...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, let’s put everything together and see how many tweets we’ve got for\n",
    "each polarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/miniconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the data frames and bar plot\n",
    "# Put everything together recomputing the index\n",
    "df = pd.concat([df, airline_df, debate_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>source</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>nltk.corpus.twitter_samples</td>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                       source  \\\n",
       "0  positive  nltk.corpus.twitter_samples   \n",
       "1  positive  nltk.corpus.twitter_samples   \n",
       "2  positive  nltk.corpus.twitter_samples   \n",
       "3  positive  nltk.corpus.twitter_samples   \n",
       "4  positive  nltk.corpus.twitter_samples   \n",
       "\n",
       "                                               tweet  \n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...  \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...  \n",
       "2  @DespiteOfficial we had a listen last night :)...  \n",
       "3                               @97sides CONGRATS :)  \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many positive/neutral/negative samples we've got\n",
    "df[['tweet', 'sentiment']].groupby(['sentiment']).count().plot(kind='bar')\n",
    "# Make sure the plot doesn't immediately disappear\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets:  67022\n"
     ]
    }
   ],
   "source": [
    "print(\"Total tweets: \", len(df))\n",
    "# Save all data to file\n",
    "df.to_csv('twitter_sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- We gathered a good amount of tweets: 38.510.\n",
    "- Data gathered comes from different areas: a great deal of them are either\n",
    "political or customer interactions tweets.\n",
    "- Missing neutral class: the NLTK annotated tweets don’t have a neutral class\n",
    "which means there might be some tweets, at least in theory, that should be\n",
    "classified as neutral.\n",
    "- Dataset is rather unbalanced, skewed towards the negative class.\n",
    "\n",
    "\n",
    "### Sentiment Analysis - A First Attempt\n",
    "We now have the data all together, so let’s train a model to predict tweet sentiments\n",
    "by taking the same approach as we did in the Text Analysis chapter.\n",
    "\n",
    "**Training a Sentiment Classifier - First Attempt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./twitter_sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.7579261469600895\n"
     ]
    }
   ],
   "source": [
    "tweets = data['tweet'].values.astype(str)\n",
    "sentiments = data['sentiment'].values.astype(str)\n",
    "# Split the data for training and for testing and shuffle it\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, sentiments,\n",
    "test_size=0.2, shuffle=True)\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True)\n",
    "# Compute the vocabulary only on the training data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the text list to a matrix form\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Vectorize the test data\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Check our classifier performance\n",
    "score = classifier.score(X_test_vectorized, y_test)\n",
    "print(\"Accuracy=\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got an accuracy of around 0.71 (71%). It’s not bad, but there are some small\n",
    "adjustments we can make to obtain better results. We’ll see how that goes in the\n",
    "next chapters.\n",
    "\n",
    "## Better Tokenization\n",
    "*How does the Vectorizer transform text into words?* According to the documentation,\n",
    "the vectorizer has two parameters of interest:\n",
    "\n",
    "- tokenizer - a function that performs tokenization on a string.\n",
    "- token_pattern - a regex for extracting tokens from a string. (this is a fallback in\n",
    "case no tokenizer function was provided)\n",
    "\n",
    "Let’s take the default value for the token_pattern which is r\"(?u)\\b\\w\\w+\\b\". and see\n",
    "how it performs on this tweet:\n",
    "\n",
    ">@BeaMiller u didn’t follow me :((\n",
    "\n",
    "**Bad Tweet Tokenization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "tweet = \"@BeaMiller u didn't follow me :((\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BeaMiller', 'didn', 'follow', 'me']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"(?u)\\b\\w\\w+\\b\", tweet))\n",
    "# ['BeaMiller', 'didn', 'follow', 'me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'BeaMiller', 'u', 'did', \"n't\", 'follow', 'me', ':', '(', '(']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.word_tokenize(tweet))\n",
    "# ['@', 'BeaMiller', 'u', 'did', \"n't\", 'follow', 'me', ':', '(', '(']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve tried both the regex token pattern and the nltk.word_tokenize, but we did\n",
    "not get satisfactory results: none of them caught the emoticon (which is a huge\n",
    "sentiment indicator) or the Twitter handle (which has no sentiment value).\n",
    "Feel free to build a better performing regex, as it would be a good exercise at this\n",
    "point.\n",
    "Moving forward, let’s use another tokenizer that comes bundled with NLTK and see\n",
    "how it performs: `nltk.tokenize.TweetTokenizer`\n",
    "\n",
    "**NLTK Tweet Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "tweet = \"@BeaMiller u didn't follow me :((\"\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@BeaMiller', 'u', \"didn't\", 'follow', 'me', ':(', '(']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(tweet))\n",
    "# ['@BeaMiller', 'u', \"didn't\", 'follow', 'me', ':(', '(']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', \"didn't\", 'follow', 'me', ':(', '(']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer(strip_handles=True)\n",
    "print(tokenizer.tokenize(tweet))\n",
    "# ['u', \"didn't\", 'follow', 'me', ':(', '(']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it’s not perfect, but it’s slightly better. Let’s try our new fancy\n",
    "tokenizer for the sentiment analysis task and see where it takes us:\n",
    "\n",
    "**Better Tweet Tokenization**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True)\n",
    "\n",
    "tweets = data['tweet'].values.astype(str)\n",
    "sentiments = data['sentiment'].values.astype(str)\n",
    "# Split the data for training and for testing and shuffle it\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets, sentiments,\n",
    "test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=True, tokenizer=tweet_tokenizer.tokenize)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.8039537486012682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Compute the vocabulary only on the training data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the text list to a matrix form\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Vectorize the test data\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Check our classifier performance\n",
    "score = classifier.score(X_test_vectorized, y_test)\n",
    "print(\"Accuracy=\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got around 0.80 accuracy (80%)! That a huge boost in accuracy with a very small\n",
    "adjustment. Pretty cool :)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
