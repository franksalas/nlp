{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn import (\n",
    "    datasets, feature_extraction, model_selection, pipeline,\n",
    "    naive_bayes, metrics\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(corpus):\n",
    "    '''Extract TF-IDF features from corpus'''\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # vectorize means we turn non-numerical data into an array of numbers\n",
    "    count_vectorizer = feature_extraction.text.CountVectorizer(\n",
    "        lowercase=True,  # for demonstration, True by default\n",
    "        tokenizer=nltk.word_tokenize,  # use the NLTK tokenizer\n",
    "        min_df=2,  # minimum document frequency, i.e. the word must appear more than once.\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=stop_words\n",
    "    )\n",
    "    processed_corpus = count_vectorizer.fit_transform(corpus)\n",
    "    processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform(\n",
    "        processed_corpus)\n",
    "\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Classes = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "19997\n",
      "Newsgroups: rec.sport.hockey\n",
      "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!uwm.edu!cs.utexas.edu!utnut!alchemy.chem.utoronto.ca!golchowy\n",
      "From: golchowy@alchemy.chem.utoronto.ca (Gerald Olchowy)\n",
      "Subject: Re: RUMOUR - Keenan signs with Rangers?\n",
      "Message-ID: <1993Apr16.222232.17393@alchemy.chem.utoronto.ca>\n",
      "Organization: University of Toronto Chemistry Department\n",
      "References: <1993Apr16.171347.784@news.columbia.edu> <1993Apr16.183110.838@alchemy.chem.utoronto.ca> <1993Apr16.185823.6310@news.columbia.edu>\n",
      "Date: Fri, 16 Apr 1993 22:22:32 GMT\n",
      "Lines: 25\n",
      "\n",
      "In article <1993Apr16.185823.6310@news.columbia.edu> gld@cunixb.cc.columbia.edu (Gary L Dare) writes:\n",
      ">\n",
      ">Interestingly, Keenan's co-coach (or is it his \"Number One\"?) on Team\n",
      ">Canada at the World Championships is Roger Neilsen.  \n",
      ">\n",
      "\n",
      "But ultimately their hockey philosophies are like night and day...\n",
      "Keenan believes in pressuring the opposition and taking the\n",
      "initiative (within the limits of his system)...while Roger\n",
      "has a reactive hockey philosophy...which is why Messier will\n",
      "be able to and has played for Keenan, but thought Roger's way\n",
      "was a sure loser.\n",
      "\n",
      ">It'd be interesting if the Rangers call in the balance of Neilsen's\n",
      ">contract to be Keenan's assistant ...  Roger did do a very good job\n",
      ">with the mediocre players, just as he handled the Cinderella Canucks\n",
      ">of 10 years ago ... but his mistake was playing the Rangers like those\n",
      ">Canucks last May ...\n",
      ">\n",
      "\n",
      "Roger is a great assistant coach...but considering what must be bad\n",
      "blood between Nielson and Messier, it would be a mistake to bring\n",
      "him back even in that role.\n",
      "\n",
      "Gerald\n",
      "\n",
      "Accuracy of multinomial naive bayes= 0.9007575757575758\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.88      0.82       333\n",
      "           comp.graphics       0.88      0.86      0.87       332\n",
      " comp.os.ms-windows.misc       0.91      0.86      0.88       342\n",
      "comp.sys.ibm.pc.hardware       0.91      0.88      0.89       341\n",
      "   comp.sys.mac.hardware       0.93      0.94      0.94       318\n",
      "          comp.windows.x       0.89      0.94      0.92       332\n",
      "            misc.forsale       0.92      0.87      0.89       358\n",
      "               rec.autos       0.94      0.94      0.94       317\n",
      "         rec.motorcycles       0.97      0.97      0.97       320\n",
      "      rec.sport.baseball       0.98      0.96      0.97       337\n",
      "        rec.sport.hockey       0.90      0.97      0.93       310\n",
      "               sci.crypt       0.91      0.98      0.95       320\n",
      "         sci.electronics       0.92      0.91      0.92       321\n",
      "                 sci.med       0.98      0.93      0.96       340\n",
      "               sci.space       0.94      0.97      0.95       338\n",
      "  soc.religion.christian       0.89      1.00      0.94       324\n",
      "      talk.politics.guns       0.86      0.94      0.90       316\n",
      "   talk.politics.mideast       0.92      0.98      0.95       335\n",
      "      talk.politics.misc       0.83      0.76      0.80       331\n",
      "      talk.religion.misc       0.71      0.51      0.59       335\n",
      "\n",
      "             avg / total       0.90      0.90      0.90      6600\n",
      "\n",
      "{'mean_fit_time': array([73.56326262, 74.38176099, 93.43620062, 93.18049932]), 'std_fit_time': array([1.39377264, 1.54397279, 1.31659498, 1.34289767]), 'mean_score_time': array([38.75101431, 38.63074112, 41.33319664, 41.17773279]), 'std_score_time': array([1.15793934, 1.14407693, 1.08382002, 1.27068087]), 'param_counts__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 2), (1, 2)],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_naivebayes__alpha': masked_array(data=[0.1, 3.0, 0.1, 3.0],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'counts__ngram_range': (1, 1), 'naivebayes__alpha': 0.1}, {'counts__ngram_range': (1, 1), 'naivebayes__alpha': 3.0}, {'counts__ngram_range': (1, 2), 'naivebayes__alpha': 0.1}, {'counts__ngram_range': (1, 2), 'naivebayes__alpha': 3.0}], 'split0_test_score': array([0.89020572, 0.86940966, 0.88685152, 0.87544723]), 'split1_test_score': array([0.89433624, 0.86389075, 0.89142601, 0.86769644]), 'split2_test_score': array([0.88918798, 0.86765366, 0.89143114, 0.87191566]), 'mean_test_score': array([0.89124431, 0.86698515, 0.88990072, 0.87168769]), 'std_test_score': array([0.00222593, 0.00230296, 0.00215841, 0.00316969]), 'rank_test_score': array([1, 4, 2, 3], dtype=int32), 'split0_train_score': array([0.97288515, 0.93109244, 0.97535014, 0.93535014]), 'split1_train_score': array([0.97043673, 0.931243  , 0.97334826, 0.93919373]), 'split2_train_score': array([0.97136145, 0.92941045, 0.97460566, 0.9343327 ]), 'mean_train_score': array([0.97156111, 0.93058196, 0.97443469, 0.93629219]), 'std_train_score': array([0.00100949, 0.00083066, 0.00082616, 0.00209332])}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    newsgroups_data = datasets.load_files(\n",
    "        '20_newsgroups', shuffle=True, random_state=42, encoding='ISO-8859-1')\n",
    "\n",
    "    print('Data loaded.\\nClasses = {classes}\\n{datapoints}'.format(\n",
    "        classes=newsgroups_data.target_names,\n",
    "        datapoints=len(newsgroups_data.data)))\n",
    "\n",
    "    print(newsgroups_data.data[0])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        newsgroups_data.data, newsgroups_data.target, test_size=0.33,\n",
    "        random_state=42)\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    model = pipeline.Pipeline([\n",
    "        ('counts', feature_extraction.text.CountVectorizer(\n",
    "            lowercase=True,  # for demonstration, True by default\n",
    "            tokenizer=nltk.word_tokenize,  # use the NLTK tokenizer\n",
    "            min_df=2,  # minimum document frequency, i.e. the word must appear more than once.\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=stop_words\n",
    "        )),\n",
    "        ('tfidf', feature_extraction.text.TfidfTransformer()),\n",
    "        ('naivebayes', naive_bayes.MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Accuracy of multinomial naive bayes= {}'.format(\n",
    "        np.mean(y_pred == y_test)))\n",
    "\n",
    "    print(metrics.classification_report(\n",
    "        y_test, y_pred, target_names=newsgroups_data.target_names))\n",
    "\n",
    "    grid_search_model = model_selection.GridSearchCV(\n",
    "        model,\n",
    "        {\n",
    "            'counts__ngram_range': [(1, 1), (1, 2)],\n",
    "            'naivebayes__alpha': (0.1, 3.0)\n",
    "        },\n",
    "        n_jobs=-1  # detect how many cores are installed and uses them all\n",
    "    )\n",
    "\n",
    "    grid_search_model.fit(X_train, y_train)\n",
    "    print(grid_search_model.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
